<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">
    
    <!-- HTML4 meta tags forcing no-caching -->
    <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate" />
    <meta http-equiv="Pragma" content="no-cache" />
    <meta http-equiv="Expires" content="0" />

    <link rel="icon" href="/favicon.ico?">

    <title>COMPSCI 697L Deep Learning</title>

    <!-- Bootstrap core CSS -->
    <link href="assets/css/bootstrap.min.css" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <link href="assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="assets/css/offcanvas.css" rel="stylesheet">

    <!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
    <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
    <script src="assets/js/ie-emulation-modes-warning.js"></script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>

  <body>
    <nav class="navbar navbar-fixed-top navbar-custom">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <!--<a class="navbar-brand" href="https://www.cics.umass.edu/">COMPSCI697L</a>-->
          <a class="navbar-brand" href="https://www.cics.umass.edu/"><img style="max-height:15px; margin-top: 1px;"
             src="/assets/fig/umasslogo2.png"></a>
          <!--<a class="navbar-brand" href="#">COMPSCI697L</a>-->
        </div>
        <div id="navbar" class="collapse navbar-collapse">
          <ul class="nav navbar-nav">
            <li><a href="/index.html">Home</a></li>
            <li class="active"><a href="/syllabus.html">Syllabus</a></li>
            <li><a href="/notes/">Notes</a></li>
            <li><a href="/assignments.html">Assignments</a></li>
            <li><a href="/projects/">Project</a></li>
          </ul>
        </div><!-- /.nav-collapse -->
      </div><!-- /.container -->
    </nav><!-- /.navbar -->

    <div class="container">
<h2>COMPSCI 697L Deep Learning</h2>
      <div class="panel panel-info">
        <div class="panel-heading">
          <h3 class="panel-title">Note</h3>
        </div>
        <div class="panel-body">
          <ul>
            <li>This is a tentative class outline and is subject to change throughout the semester. </li>
            <li>Slides will be posted after each lecture.</li>
          </ul>
        </div>
      </div>
        <div class="panel panel-default">
<table class="table">
  <tbody><tr class="active">
    <th>Event Type</th><th>Date</th><th>Description</th><th>Course Materials</th>
  </tr>
  <tr>
    <td>Lecture</td>
    <td>Sep 7</td>
    <td>Intro to Deep Learning, historical context.</td>
    <td>
	<a href="https://docs.google.com/presentation/d/1l6VCpuOA1AlJAjZ-6tsGRd-YTojxMaRVPCYI2sWe3Dg/edit?usp=sharing">[slides]</a><br>
	<a href="notes/python-numpy-tutorial/">[python/numpy tutorial]</a><br>
	<a href="notes/jupyter-tutorial/">[jupyter tutorial]</a>
    </td>
  </tr>
  <tr>
    <td>Lecture</td>
    <td>Sep 12</td>
    <td>Image classification and the data-driven approach <br> k-nearest neighbor <br> Linear classification I</td>
    <td>
    <a href="https://docs.google.com/presentation/d/10vfD1Q9wfZcVUU_uG5uhdnbnk5nocRz__B5AoHxWNlI/edit?usp=sharing">[slides]</a><br>
    <a href="notes/classification/">[image classification notes]</a><br>
    <a href="notes/linear-classify/">[linear classification notes]</a><br>
    </td>
  </tr>
  <tr>
    <td>Lecture</td>
    <td>Sep 14</td>
    <td>
     Linear classification II<br>
    </td>
    <td>
      <a href="https://docs.google.com/presentation/d/1JRqOoslZ1T8cIqBxL8oHoz2F9wZ_v3al0yWpWmyyo4w/edit?usp=sharing">[slides]</a><br>
      <a href="notes/linear-classify/">[linear classification notes]</a>
    </td>
  </tr>
  <tr>
    <td>Lecture</td>
    <td>Sep 19</td>
    <td>
        Loss functions<br>
        Optimization I: Stochastic gradient descent
    </td>
    <td>
      <a href="https://docs.google.com/presentation/d/1kQmh9T8t7n2ogJuLtVKWNswe24wdxHALvPDUK6j1abc/edit?usp=sharing">[slides]</a><br>
      <a href="notes/optimization-1/">[optimization notes]</a>
    </td>
  </tr>
  <tr>
  <tr>
    <td>Lecture</td>
    <td>Sep 21</td>
    <td>
        Backpropagation &amp; Neural Networks I
    </td>
    <td>
      <a href="https://docs.google.com/presentation/d/1oudCntxqxQpH-yPmPhqEvmyqlaa8EahsMjbhvwg4W_U/edit?usp=sharing">[slides]</a><br>
      <a href="notes/optimization-2/">[backprop notes]</a><br>
      <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf">[Efficient BackProp]</a> (optional)<br>
      related: <a href="http://colah.github.io/posts/2015-08-Backprop/">[1]</a>, <a href="http://neuralnetworksanddeeplearning.com/chap2.html">[2]</a>, <a href="https://www.youtube.com/watch?v=q0pm3BrIUFo">[3]</a> (optional)
    </td>
  </tr>
  <tr>
    <td>Lecture</td>
    <td>Sep 26</td>
    <td>
        Higher-level representations, image features<br>
        Vector, Matrix, and Tensor Derivatives
    </td>
    <td>
      <a href="/docs/vecDerivs.pdf">[handout]</a><br>
      <a href="https://docs.google.com/presentation/d/1h_7jVx-75vfs6m5qbyr4T1M13bbya_K505_jEfXRpAA/edit?usp=sharing">[slides]</a><br>
      <a href="http://www.nature.com/nature/journal/v521/n7553/full/nature14539.html">Deep Learning [Nature]</a> (optional)
    </td>
  </tr>
  <tr>
    <td>Lecture</td>
    <td>Sep 28</td>
    <td>
        Backpropagation &amp; Neural Networks II
    </td>
    <td>
      <a href="https://docs.google.com/presentation/d/1h_7jVx-75vfs6m5qbyr4T1M13bbya_K505_jEfXRpAA/edit?usp=sharing">[slides]</a> (cont.)<br> 
      tips/tricks:
      <a href="http://research.microsoft.com/pubs/192769/tricks-2012.pdf">[1]</a>,
      <a href="http://arxiv.org/pdf/1206.5533v2.pdf">[2]</a> (optional)
      <br>
    </td>
  </tr>
  <tr>
    <td>Lecture</td>
    <td>Oct 3</td>
    <td>
        Training Neural Networks I
    </td>
    <td>
        <a href="https://docs.google.com/presentation/d/1-EIQUEk7unzawJ-iK0PmpQaveLK2uLdc7EDF6wUJOvA/edit?usp=sharing">[slides]</a><br> 
        <a href="notes/neural-networks-1/">[Neural Nets notes 1]</a>
    </td>
  </tr>
  <tr>
    <td>Lecture</td>
    <td>Oct 5</td>
    <td>
        Training Neural Networks II
    </td>
    <td>
      <a href="https://docs.google.com/presentation/d/1V2lgXXXFs_1qRe77XP9PUzvEUCrZ1L5BRAQc4CRZoz8/edit?usp=sharing">[slides]</a><br> 
      <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf">LeNet</a> (optional)
    </td>
  </tr>
  <tr class="info">
    <td>No class</td>
    <td>Oct 10</td>
    <td>Columbus Day; Class will be on Tuesday (Oct 11) instead.</td>
    <td></td>
  </tr>
  <tr>
    <td>Lecture</td>
    <td>Oct 11</td>
    <td>
        Training Neural Networks III: <br>
        weight initialization, batch normalization
    </td>
    <td>
        <a href="https://docs.google.com/presentation/d/1UhJiujgYX1Z51tFtLprhYGOZZRoKB8Fur91NT580Cvk/edit?usp=sharing">[slides]</a><br> 
        <a href="notes/neural-networks-2/">[Neural Nets notes 2]</a><br>
        <a href="https://arxiv.org/abs/1502.03167">[Batch Norm]</a><br>
    </td>
  </tr>
  <tr>
    <td>Lecture</td>
    <td>Oct 12</td>
    <td>
        Training Neural Network IV: <br>
        babysitting the learning process, hyperparameter optimization
    </td>
    <td>
        <a href="https://docs.google.com/presentation/d/1yCF-mHZpPdCOh5YHp0m5YoyrQLzIcF_iymTXLEjiLCk/edit?usp=sharing">[slides]</a><br> 
        <a href="notes/neural-networks-3/">[Neural Nets notes 3]</a>
    </td>
  </tr>
  <tr>
    <td>Lecture</td>
    <td>Oct 17</td>
    <td>
        Training Neural Network IV (cont.): <br>
        babysitting the learning process, hyperparameter optimization
    </td>
    <td>
        <a href="https://docs.google.com/presentation/d/1yCF-mHZpPdCOh5YHp0m5YoyrQLzIcF_iymTXLEjiLCk/edit?usp=sharing">[slides]</a> (cont.)<br> 
        <a href="https://arxiv.org/abs/1206.5533">[Bengio 2012]</a> (optional)<br>
    </td>
  </tr>
  <tr>
    <td>Lecture</td>
    <td>Oct 19</td>
    <td>
        Project announcement <br>
        Training Neural Network V: <br>
        parameter updates, model ensembles, dropout
    </td>
    <td>
        <a href="https://docs.google.com/presentation/d/1wA0TwJ_Gd4rIwelljTvcVdc5gCUi5taKBPl2PZkUXME/edit?usp=sharing">[slides]</a><br> 
        <a href="http://cs231n.stanford.edu/reports.html">[Stanford cs231n project reports]</a>
    </td>
  </tr>
  <tr>
    <td>Lecture</td>
    <td>Oct 24</td>
    <td>
      Convolutional Neural Networks: introduction, history, architectures
    </td>
    <td>
        <a href="https://docs.google.com/presentation/d/1mijEyEIKPj8rhfb_CLLs45ZAVGzx_c-7mMiDynCiSE4/edit?usp=sharing">[slides]</a><br> 
        <a href="notes/convolutional-networks/">[ConvNet notes]</a> <br>
        <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">AlexNet</a> (optional) 
    </td>
  </tr>
  <tr>
    <td>Guest Lecture</td>
    <td>Oct 26</td>
    <td> <a href="https://people.cs.umass.edu/~tsungyulin/">Tsung-Yu Lin</a>: Bilinear CNN
    </td>
    <td>
        <a href="https://drive.google.com/file/d/0B-0OtUj_Gj7nOHVNSjJ3OVFCdUU/view?usp=sharing">[slides]</a><br>
        <a href="https://arxiv.org/abs/1504.07889">BCNN</a> (optional)
    </td>
  </tr>
  <tr>
    <td>Lecture</td>
    <td>Oct 31</td>
    <td>
        Convolutional Neural Networks: convolution layer, pooling layer, fully connected layer <br>
        Case study of ImageNet challenge winning ConvNets
   </td>
    <td>
        <a href="https://docs.google.com/presentation/d/1mijEyEIKPj8rhfb_CLLs45ZAVGzx_c-7mMiDynCiSE4/edit?usp=sharing">[slides]</a> (cont.)<br> 
        <a href="https://drive.google.com/file/d/0B-0OtUj_Gj7namdSdDZsVXdnLTl6YWlJaTdkODc2eWZMT1Nv/view?usp=sharing">[midterm review sheet]</a>
    </td>
  </tr>
  <tr class="danger">
    <td>Midterm</td>
    <td>Nov 2</td>
    <td>
        In-class midterm<br> 
        Project proposals due!
    </td>
    <td>
        <a href="https://docs.google.com/spreadsheets/d/1X8A8FrB0T6zfT6-xekzqrVK3h67jf78mUQUP52ogxKw/edit?usp=sharing">Proposed project topics</a>
    </td>
  </tr>
  <tr>
    <td>Lecture</td>
    <td>Nov 7</td>
    <td>
        Case study of ImageNet challenge winning ConvNets (cont.) <br>
        ConvNets for spatial localization, Object detection
    </td>
    <td>
        <a href="https://docs.google.com/presentation/d/17P1pFTG7seo6EuDhLrJDI6Bb7ce1_mUd28qhJKe5j_k/edit?usp=sharing">[slides]</a><br>
        <a href="https://arxiv.org/abs/1512.03385">ResNet</a> (optional)
    </td>
  </tr>
  <tr>
    <td>Lecture</td>
    <td>Nov 9</td>
    <td>
      ConvNets for spatial localization, Object detection (cont.)
    </td>
    <td>
        <a href="https://docs.google.com/presentation/d/17P1pFTG7seo6EuDhLrJDI6Bb7ce1_mUd28qhJKe5j_k/edit?usp=sharing">[slides]</a> (cont.)<br>
        <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf">FCN</a> (optional)
    </td>
  </tr>
  <tr>
    <td>Lecture</td>
    <td>Nov 14</td>
    <td>
      Understanding and visualizing Convolutional Neural Networks<br>
      Backprop into image: Visualizations, deep dream
    </td>
    <td>
        <a href="https://docs.google.com/presentation/d/16VDgX6BwCkJvsJOxKAcjFFbnfWb3A2069gyGOwHWSXY/edit?usp=sharing">[slides]</a><br>
        <a href="notes/understanding-cnn/">[visualization notes]</a> 
    </td>
  </tr>
  <tr class="info">
    <td>No class</td>
    <td>Nov 16</td>
    <td>
      Friday schedule; No class.
    </td>
    <td>
    </td>
  </tr>
  <tr class="info">
    <td>No class</td>
    <td>Nov 21</td>
    <td>
      Thanksgiving; No class.
    </td>
    <td>
    </td>
  </tr>
  <tr class="info">
    <td>No class</td>
    <td>Nov 23</td>
    <td>
      Thanksgiving; No class.
    </td>
    <td>
    </td>
  </tr>
  <tr>
    <td>Lecture</td>
    <td>Nov 28</td>
    <td>
      Artistic style transfer<br>
      Adversarial fooling examples<br>
      Recurrent Neural Networks (RNN)
    </td>
    <td>
      <a href="https://docs.google.com/presentation/d/1tv3BCnd8hGk4O_1Rmi4qx2AWinDdYM4dxyS-FMlDlZI/edit?usp=sharing">[slides]</a><br>
      <a href="http://www.deeplearningbook.org/contents/rnn.html">DL book RNN chapter</a> (optional)<br>
      <a href="https://gist.github.com/karpathy/d4dee566867f8291f086">min-char-rnn</a>, <a href="https://github.com/karpathy/char-rnn">char-rnn</a>, <a href="https://github.com/karpathy/neuraltalk2">neuraltalk2</a>
    </td>
  </tr>
  <tr>
    <td>Lecture</td>
    <td>Nov 30</td>
    <td>
      Recurrent Neural Networks (RNN) (cont.) <br>
      Long Short Term Memory (LSTM)
    </td>
    <td>
      <a href="https://docs.google.com/presentation/d/1tv3BCnd8hGk4O_1Rmi4qx2AWinDdYM4dxyS-FMlDlZI/edit?usp=sharing">[slides]</a> (cont.)<br>
      <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of RNN</a> (optional)
    </td>
  </tr>
  <tr>
    <td>Lecture</td>
    <td>Dec 5</td>
    <td>
        Long Short Term Memory (LSTM) (cont.)
    </td>
    <td>
      <a href="https://docs.google.com/presentation/d/1tv3BCnd8hGk4O_1Rmi4qx2AWinDdYM4dxyS-FMlDlZI/edit?usp=sharing">[slides]</a> (cont.)<br>
      <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a> (optional)
    </td>
  </tr>
  <tr>
    <td>Lecture</td>
    <td>Dec 7</td>
    <td>
      Training ConvNets in practice
    </td>
    <td>
        <a href="https://docs.google.com/presentation/d/1mMXpk2DVgTqoArOyvm35U-DnW7-X5gCqXZIqhyH4up4/edit?usp=sharing">[slides]</a><br>
    </td>
  </tr>
  <tr>
    <td>Lecture</td>
    <td>Dec 12</td>
    <td>
      Additional topics in Stanford cs231n <br>
      Societal implications of AI
    </td>
    <td>
        <a href="https://docs.google.com/presentation/d/1qTtKDajhlb5fJfXDDKNGy1C5uqOOvlNSKt4qUfZlseM/edit?usp=sharing">[slides]</a><br>
        Stanford cs231n slides not covered in our course: <a href="https://drive.google.com/file/d/0B-0OtUj_Gj7nY2toWTZIekZyRkk/view?usp=sharing">Software Packages</a>, <a href="https://drive.google.com/file/d/0B-0OtUj_Gj7nazc5ajZhZzhKTnM/view?usp=sharing">Segmentation & Attention</a>, <a href="https://drive.google.com/file/d/0B-0OtUj_Gj7nbVRkbm1tUnRUanM/view?usp=sharing">Videos & Unsupervised Learning</a>
    </td>
  </tr>
  <tr class="danger">
    <td>Presentation</td>
    <td>Dec 14</td>
    <td>
      Poster presentations at room 150/151
    </td>
    <td>
        <a href="https://docs.google.com/spreadsheets/d/1X8A8FrB0T6zfT6-xekzqrVK3h67jf78mUQUP52ogxKw/edit?usp=sharing">schedule</a>
    </td>
  </tr>
</tbody></table>
</div>

    </div><!--/.container-->

    <footer class="site-footer">
      <div class="wrap">
        <div class="footer-col-1 column">
          <ul>
            <li><a href="https://github.com/compsci697l">
              <span class="icon github">
                <svg version="1.1" class="github-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                   viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                  <path fill-rule="evenodd" clip-rule="evenodd" fill="#C2C2C2" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761
                  c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32
                  c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472
                  c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037
                  C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65
                  c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261
                  c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082
                  c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129
                  c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
                </svg>
              </span>
              <span class="username">compsci697l</span>
            </a>
            </li>
            <li>
              <a href="mailto:compsci697l@gmail.com">compsci697l@gmail.com</a>
            </li>
          </ul>
        </div>
        <div class="footer-col-2 column">

        </div>

        <div class="footer-col-3 column">

        </div>
      </div>
    </footer>

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="assets/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="assets/js/ie10-viewport-bug-workaround.js"></script>
    <script src="assets/js/offcanvas.js"></script>
  </body>
</html>
